{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "214c0f1b",
   "metadata": {},
   "source": [
    "# Explain Dataset\n",
    "\n",
    "#### Acc_Intakes.csv \n",
    "- Age Upon Intake: The age of the animal when it was brought to the facility\n",
    "- Animal ID: A unique identifier for each animal.\n",
    "- Animal Type: The species of the animal. In both examples, this is 'Dog'.\n",
    "- Breed: The breed of the animal.\n",
    "- Color: The color of the animal's coat.\n",
    "- Datetime: The date and time when the animal was intake.\n",
    "- Datetime2: This seems to be a repeat of the intake date and time\n",
    "- Found Location: The location where the animal was found before being brought to the facility.\n",
    "- Intake Condition: The health or physical condition of the animal at intake.\n",
    "- Intake Type: The circumstances under which the animal was brought to the facility.\n",
    "- Name: The name given to the animal. \n",
    "- Sex Upon Intake: The gender and reproductive status of the animal when it arrived.\n",
    "\n",
    "#### Acc_Outcomes.csv\n",
    "- Age Upon Outcome: This is the age of the animal at the time they left the facility\n",
    "- Animal ID: A unique identifier assigned to each animal.\n",
    "- Animal Type: The species of the animal.\n",
    "- Breed: The breed of the animal.\n",
    "- Color: The color of the animal's coat.\n",
    "- Date of Birth: The birth date of the animal. \n",
    "- Datetime: The date and time when the animal left the facility.\n",
    "- Monthyear: This seems to be a repeat of the outcome date and time\n",
    "- Name: The name of the animal\n",
    "- Outcome Subtype: Additional details about the outcome.\n",
    "- Outcome Type: The general category of the outcome.\n",
    "- Sex Upon Outcome: The gender and reproductive status of the animal when it left the facility. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ecbdd7",
   "metadata": {},
   "source": [
    "# Clearn data before analyze.\n",
    "#### Import pandas and numpy library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "884373c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ace7b6c",
   "metadata": {},
   "source": [
    "#### Read file aac_intakes.csv and save as 'aac_intakes' dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e120912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "C:\\Users\\lemin\\AppData\\Local\\Temp\\ipykernel_13352\\2692003013.py:2: SyntaxWarning: invalid escape sequence '\\D'\n",
      "  output_data=pd.read_csv('C:\\\\Users\\\\lemin\\\\Downloads\\Day_5 (1)\\\\Demo\\\\aac_outcomes.csv')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\lemin\\\\Downloads\\\\Day_5 (1)\\\\Demo\\\\aac_intakes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m input_data\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mlemin\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDownloads\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDay_5 (1)\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43mDemo\u001b[39;49m\u001b[38;5;130;43;01m\\\\\u001b[39;49;00m\u001b[38;5;124;43maac_intakes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m output_data\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mlemin\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDownloads\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDay_5 (1)\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mDemo\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124maac_outcomes.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\lemin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\lemin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\lemin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\lemin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\lemin\\\\Downloads\\\\Day_5 (1)\\\\Demo\\\\aac_intakes.csv'"
     ]
    }
   ],
   "source": [
    "input_data=pd.read_csv('C:\\\\Users\\\\lemin\\\\Downloads\\\\Day_5 (1)\\\\Demo\\\\aac_intakes.csv')\n",
    "output_data=pd.read_csv('C:\\\\Users\\\\lemin\\\\Downloads\\Day_5 (1)\\\\Demo\\\\aac_outcomes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0194cfc",
   "metadata": {},
   "source": [
    "Let's have a look at dataframe and change data type as neededneeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14831b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e57930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change data type of input_data\n",
    "input_data[['datetime','datetime2']]=input_data[['datetime','datetime2']].apply(pd.to_datetime)\n",
    "input_data.info()\n",
    "input_data.sort_values(by='datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3583012b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.info()\n",
    "output_data[['date_of_birth','datetime','monthyear']]=output_data[['date_of_birth','datetime','monthyear']].apply(pd.to_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dac468f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c92a1",
   "metadata": {},
   "source": [
    "Duplicated rows can be removed before analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b5b394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check duplicates, and see how data is duplicated\n",
    "input_data_dup=input_data[input_data.duplicated(keep=False)]\n",
    "input_data_dup.sort_values(by='animal_id').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate\n",
    "input_data=input_data.drop_duplicates()\n",
    "input_data.sort_values(by='animal_id').head(10)\n",
    "input_data.shape\n",
    "input_data=input_data.dropna(subset=['animal_id','datetime','datetime2'])\n",
    "input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cde31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data_up = input_data .sort_values(by='datetime', ascending=False)  # Sort by date (latest first)\n",
    "input_data_up = input_data.drop_duplicates(subset='animal_id', keep='first')  # Keep the first (latest)\n",
    "input_data_up.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd706634",
   "metadata": {},
   "source": [
    "Similar to acc_outcome, we will remove duplicate entry uupdate the latest time of the animal intakes with the latest time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f50352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data=output_data.drop_duplicates()\n",
    "output_data=output_data.dropna(subset=['animal_id'])\n",
    "output_data=output_data.sort_values(by='datetime', ascending=False)  # Sort by date (latest first)\n",
    "output_data= output_data.drop_duplicates(subset='animal_id', keep='first')  # Keep the first (latest)\n",
    "output_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c53429",
   "metadata": {},
   "source": [
    "# Answers question"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ffdad46",
   "metadata": {},
   "source": [
    "#### Question number 1: What is the distribution of the types of animals in the shelter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af9436a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c98bf88",
   "metadata": {},
   "source": [
    "#### Question number 2: Is there an area where more pets are found?. Find the top 5 location where pet are found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937afda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cach1: get the first afer sorting valuesvalues\n",
    "count_location=input_data.groupby('found_location')['animal_id'].count().sort_values(ascending=False).head(5)\n",
    "count_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6255ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cach 2: can get the value with the same result at top 5\n",
    "location_group=input_data['found_location'].value_counts()\n",
    "threshold=location_group.iloc[4]\n",
    "top_5=location_group[location_group>=threshold]\n",
    "top_5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557cb3d",
   "metadata": {},
   "source": [
    "#### Question number 3: What is the average number of pets found in a month in the year 2015?. Are there months where there is a higher number of animals found?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db62d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter data for 2015\n",
    "data_2015 = input_data[(input_data['datetime'] >= \"2015-01-01\") & (input_data['datetime'] <= \"2015-12-31\")]\n",
    "\n",
    "# Calculate the average number of found animals per month in 2015\n",
    "avg_2015 = data_2015.groupby(data_2015['datetime'].dt.month)['animal_id'].count().mean()\n",
    "print(f\"Average number of animals found per month in 2015: {avg_2015}\")\n",
    "\n",
    "# Group by month and count occurrences of 'animal_id'\n",
    "animal_2015 = data_2015.groupby(data_2015['datetime'].dt.month)['animal_id'].count().sort_values()\n",
    "\n",
    "# Get the highest number of found animals in a single month (top 1)\n",
    "top_1 = animal_2015.iloc[0]  # Highest number of found pets in a month\n",
    "month_1 = animal_2015[animal_2015 == top_1]  # Get the months with the top count\n",
    "months= ','.join(map(str, month_1.index.tolist()))\n",
    "# Convert months to a string without square brackets\n",
    "months = ', '.join(map(str, month_1.index.tolist()))\n",
    "\n",
    "# Print the month(s) and the number of found pets\n",
    "print(f\"The month(s) with the highest number of found pets in 2015 is/are: {months} with {top_1} found pets.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3541ec",
   "metadata": {},
   "source": [
    "#### Question number 4: What is the ratio of incoming pets vs. adopted pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858bb434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of animals incoming\n",
    "in_animal=input_data_up.shape[0]\n",
    "# Number of adopted pets\n",
    "out_animal=output_data[output_data['outcome_type']=='Adoption'].shape[0]\n",
    "print ('Ratio of incoming pets and adopted pets', round(100*out_animal/in_animal,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ea009f",
   "metadata": {},
   "source": [
    "#### Question number 5: What are the adoption rates for specific breeds?\n",
    "#### Find the top 5 dog breeds in the shelter (based on count) and then find the adoption percentage of each breed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd44da11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# total intakes of dog breedsbreeds\n",
    "dog_data=input_data_up[input_data_up['animal_type']=='Dog']\n",
    "breed_count=dog_data['breed'].value_counts()\n",
    "threshold=breed_count.iloc[4]\n",
    "top_5=breed_count[breed_count>=threshold]\n",
    "top_5_df = top_5.reset_index()  # Converts the Series to DataFrame\n",
    "top_5_df.columns = ['breed', 'intakes']  # Rename the columns\n",
    "\n",
    "top_5_intakes=top_5.index.to_list()\n",
    "## Find the adoption for dog breedsbreeds\n",
    "dog_outcome = output_data[(output_data['animal_type'] == 'Dog') & (output_data['outcome_type'] == 'Adoption')]\n",
    "\n",
    "dict_dog = {}\n",
    "\n",
    "# Assuming top_5_intakes is a list of the top 5 breed values\n",
    "for i in top_5_intakes:\n",
    "    count_breed = dog_outcome[dog_outcome['breed'] == i].shape[0]  # Count occurrences of breed\n",
    "    dict_dog[i] = count_breed  # Add breed and its count to the dictionary\n",
    "\n",
    "# Convert dictionary to DataFrame for better readability\n",
    "dog_df = pd.DataFrame(list(dict_dog.items()), columns=['breed', 'adoption count'])\n",
    "merged_df = pd.merge(dog_df, top_5_df, on='breed', how='inner')\n",
    "merged_df['Adoption Rate']=merged_df['adoption count']*100/merged_df['intakes'] \n",
    "merged_df['Adoption Rate'] = round(merged_df['Adoption Rate'],2).astype(str) + ' %'\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f847d1e",
   "metadata": {},
   "source": [
    "#### Question number 6: About how many animals are spayed/neutered each month?\n",
    "#### This will help the shelter allocate resources and staff. Assume that all intact males and females will be spayed/neutered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f5878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Slice data to sex_intakess, sex_outcomes\n",
    "\n",
    "sex_intakes=input_data_up[['animal_id','sex_upon_intake']]\n",
    "sex_outcomes_new=output_data[['animal_id','sex_upon_outcome','monthyear']]\n",
    "print(sex_intakes.shape[0])\n",
    "print(sex_outcomes_new.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8694b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the animals are spayed or neutered by staff\n",
    "#Step 1:Find the animals that haven't been spayed before\n",
    "#Step 2: Find the animals that have been spay after outcomes\n",
    "#Step 3: Filter data based on step1, step 2\n",
    "sex_intakes['sex_upon_intake'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af029c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1:Find the animals that haven't been spayed before\n",
    "intake_no_spay = sex_intakes[\n",
    "    (sex_intakes['sex_upon_intake'] != 'Spayed Female') & \n",
    "    (sex_intakes['sex_upon_intake'] != 'Neutered Male')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079cd948",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Find the animals that have been spay after outcomes\n",
    "outcome_spay=sex_outcomes_new[\n",
    "        (sex_outcomes_new['sex_upon_outcome'] == 'Spayed Female') |\n",
    "    (sex_outcomes_new['sex_upon_outcome'] == 'Neutered Male')\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b487b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_data=pd.merge(intake_no_spay,outcome_spay,how ='inner', on =['animal_id'])\n",
    "intersection_data['month_year'] = intersection_data['monthyear'].dt.strftime('%Y-%m')\n",
    "month_number=intersection_data['month_year'].nunique()\n",
    "print('Average animals that are spayed or neuteredutered each month', round(intersection_data.shape[0]/month_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eed4eef",
   "metadata": {},
   "source": [
    "#### Question number 7\n",
    "How many animals in the shelter are repeats?, Which animal was returned to the shelter the most?\n",
    "This means the animal has been brought in more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c92a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_in = input_data.animal_id\n",
    "ids_out = output_data.animal_id\n",
    "\n",
    "Duprows_aac_intakes = input_data[ids_in.isin(ids_in[ids_in.duplicated()])].sort_values(\"animal_id\")\n",
    "Duprows_aac_outcomes = output_data[ids_out.isin(ids_out[ids_out.duplicated()])].sort_values(\"animal_id\")\n",
    "Duprows_aac_intakes.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf6f0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In aac_intakes, we find the most animal_type was returned to the shelter\n",
    "id_in_dup = input_data[input_data['animal_id'].duplicated()]['animal_id']\n",
    "dup_id=input_data[input_data['animal_id'].isin(id_in_dup)]\n",
    "print('There are', dup_id.shape[0] ,'animals in the shelter that are repeats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e93171b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_repeat=dup_id['animal_type'].value_counts()\n",
    "print(top_repeat.index[0], 'having the highest times of return', top_repeat.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2febf43",
   "metadata": {},
   "source": [
    "#### Question number 8\n",
    "What are the adoption rates for different colorings?\n",
    "Find the top 5 colorings in the shelter (based on count) and then find the adoption percentage of each color.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a989af60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rewrite in different solution\n",
    "# Find rows have 'Dog' breed in shelter\n",
    "dog_data=input_data_up[input_data_up['animal_type']=='Dog']\n",
    "# Find the top 5 'Dog' color in shelter\n",
    "top_5_color=dog_data.groupby('color')['animal_id'].count().sort_values(ascending=False).head(5)\n",
    "# Create a list of values from top_5_colorcolor other way:\n",
    "list_values_top5=[]\n",
    "for i in range(0, top_5_color.shape[0]):\n",
    "    value_top=top_5_color.iloc[i]\n",
    "    list_values_top5.append(value_top)\n",
    "\n",
    "\n",
    "# List values find the number of top 5 dogs in shelter had record in breedDog_outcomes\n",
    "#Step 1: filter data by type='Dog' and 'Adoption'\n",
    "dog_adoption=output_data[(output_data['animal_type']=='Dog')& (output_data['outcome_type']=='Adoption')]\n",
    "#Step 2: Group by color:\n",
    "dog_adoption_color=dog_adoption['color'].value_counts()\n",
    "#Step 3: Loop over index but index of color of adoption is the same color as top5\n",
    "list_adoption_top5=[]\n",
    "for values in top_5_color.index:\n",
    "    data_row = dog_adoption_color[dog_adoption_color.index == values]\n",
    "    value_row=data_row.loc[values]\n",
    "    list_adoption_top5.append(value_row)\n",
    "print(list_adoption_top5)\n",
    "print(list_values_top5)\n",
    "top_5_list=top_5_color.index.tolist()\n",
    "# Link all lists together:\n",
    "top5_color_df=pd.DataFrame(list(zip(top_5_list,list_values_top5,list_adoption_top5)), columns=['color','total animals','adoption number'])\n",
    "top5_color_df['adoption rate']=round(top5_color_df['adoption number']*100/top5_color_df['total animals'],2).astype(str)+'%'\n",
    "top5_color_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51935417",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "top_5_color_list=top_5_color.index\n",
    "top_5_adoption=dog_adoption_color[dog_adoption_color.index.isin(top_5_color_list)]\n",
    "\n",
    "# Step 1: Convert Series to DataFrames\n",
    "df_top_5_color = pd.DataFrame(top_5_color)  # This will create a DataFrame with one column\n",
    "df_top_5_color.columns = ['total_animals']  # Renaming the column for clarity\n",
    "df_top_5_color.reset_index(inplace=True) # Add color as a new column\n",
    "\n",
    "# Step 2: Data Frame of number of adoptions\n",
    "df_top_5_adoption = pd.DataFrame(top_5_adoption)  # This will create a DataFrame with one column\n",
    "df_top_5_adoption.columns = ['total_adoption']  # Renaming the column for clarity\n",
    "df_top_5_adoption.reset_index(inplace=True) \n",
    "# Step 3: Merge the DataFrames on 'color'\n",
    "merged_data=pd.merge(df_top_5_adoption,df_top_5_color, how='inner', on='color')\n",
    "# Perform the division to calculate the adoption rate\n",
    "merged_data['adoption_rate'] = round((merged_data['total_adoption'] * 100 / merged_data['total_animals']),2)\n",
    "\n",
    "# Add '%' symbol to the adoption rate\n",
    "merged_data['adoption_rate'] = merged_data['adoption_rate'].astype(str) + '%'\n",
    "\n",
    "# Display the updated merged data\n",
    "print(merged_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bab016",
   "metadata": {},
   "source": [
    "#### Question number 9\n",
    "What are the adoption rates for the following age groups?\n",
    "- baby: 4 months and less\n",
    "- young: 5 months - 2 years\n",
    "- adult: 3 years - 10 years\n",
    "- senior: 11+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e4803f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adoption_age_group=output_data[output_data['outcome_type']=='Adoption']\n",
    "#ignore entries having na values\n",
    "adoption_age_group=adoption_age_group[adoption_age_group['age_upon_outcome'].notna()]\n",
    "#Find data have month\n",
    "adoption_month=adoption_age_group[adoption_age_group['age_upon_outcome'].str.contains('month')]\n",
    "#Find data have year\n",
    "adoption_year=adoption_age_group[adoption_age_group['age_upon_outcome'].str.contains('year')]\n",
    "\n",
    "Lower_1_month =adoption_age_group[adoption_age_group['age_upon_outcome'].str.contains('week|day')]\n",
    "\n",
    "#### Filter the data between baby, young, aldult and senior animal by index number.\n",
    "\n",
    "list_Baby_index = []\n",
    "list_Young_index = []\n",
    "list_Aldult_index = []\n",
    "list_Senior_index = []\n",
    "\n",
    "##Find data in age_upon_months datafame\n",
    "# Between 1 month and 1 year\n",
    "list_Baby_index = []  # Initialize the list\n",
    "\n",
    "for i in range(adoption_month.shape[0]):  # Loop through all rows\n",
    "    value_i_list = adoption_month['age_upon_outcome'].iloc[i].split(' ')  # Split the string by space\n",
    "    extracted_month = int(value_i_list[0])  # Convert to integer\n",
    "    \n",
    "    if extracted_month < 5:  # Check if the extracted month is less than 5\n",
    "        list_Baby_index.append(adoption_month.age_upon_outcome.index[i])  # Append the index i to the list\n",
    "\n",
    "    else: \n",
    "         list_Young_index.append(adoption_month.age_upon_outcome.index[i]) \n",
    "for x in range(adoption_year.shape[0]):  # Loop through all rows\n",
    "    value_x_list = adoption_year['age_upon_outcome'].iloc[x].split(' ')  # Split the string by space\n",
    "    extracted_year = int(value_x_list[0])  # Convert to integer\n",
    "    \n",
    "    if extracted_year <=2:  \n",
    "        list_Young_index.append(adoption_month.age_upon_outcome.index[x])\n",
    "\n",
    "    elif extracted_year<=10: \n",
    "         list_Aldult_index .append(adoption_month.age_upon_outcome.index[x]) \n",
    "    else: list_Senior_index.append(adoption_month.age_upon_outcome.index[x]) \n",
    "    \n",
    "print('Baby rate: ',round(100 / adoption_age_group.shape[0] * int(len(list_Baby_index) + Lower_1_month.shape[0]),3), '%')\n",
    "print('Young rate: ',round(100 / adoption_age_group.shape[0] * int(len(list_Young_index)),3), '%')\n",
    "print('Aldult rate: ',round(100 / adoption_age_group.shape[0] * int(len(list_Aldult_index)),3), '%')\n",
    "print('Senior rate: ',round(100 / adoption_age_group.shape[0] * int(len(list_Senior_index)),3), '%')   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbade4df",
   "metadata": {},
   "source": [
    "#### Question number 10:\n",
    "If spay/neuter for a dog costs $100 and a spay/neuter for a cat costs $50,\n",
    "how much did the shelter spend in 2015 on these procedures?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e059f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "intersection_data_2015= intersection_data[(intersection_data['monthyear'] > \"2015-01-01\") & (intersection_data['monthyear']< \"2015-12-31\")]\n",
    "intersection_data_2015_type=pd.merge(intersection_data_2015, output_data, how='inner', on='animal_id')\n",
    "intersection_data_2015_type.drop_duplicates()\n",
    "\n",
    "a=intersection_data_2015_type.groupby('animal_type')['animal_id'].count()\n",
    "# Filter data for 2015, 6072\n",
    "intersection_data_2015 = intersection_data[(intersection_data['monthyear'] > \"2015-01-01\") & (intersection_data['monthyear'] < \"2015-12-31\")]\n",
    "\n",
    "# Merge with output_data on 'animal_id'\n",
    "intersection_data_2015_type = pd.merge(intersection_data_2015, output_data, how='inner', on='animal_id')\n",
    "\n",
    "# Group by 'animal_type' and count 'animal_id'\n",
    "a = intersection_data_2015_type.groupby('animal_type')['animal_id'].count()\n",
    "\n",
    "total_sum = 0\n",
    "for x,y in a.items():\n",
    "    if x == 'Cat':\n",
    "        total_sum += y * 50  # Add 50 for each 'Cat'\n",
    "    elif x == 'Dog':\n",
    "        total_sum += y * 100  # Add 100 for each 'Dog'\n",
    "\n",
    "print(\"Total Sum:\", total_sum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
